sample_id	val_mse	val_acc	val_mape	test_mse	test_acc	test_mape	config
1	5.557333946228027	0.4957090921285191	184.46173667907715	4.195560455322266	0.5240641711229946	103.73660326004028	{'nn.hidden_size': 512, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.5, 'train.epoch': 40, 'train.batch_size': 512, 'train.lr': 0.00030000000000000003}
2	4.737427711486816	0.49876120439338467	121.88612222671509	4.0928053855896	0.48128342245989303	107.52561092376709	{'nn.hidden_size': 1024, 'nn.output_size': 1, 'nn.num_layer': 2, 'nn.drop_prob': 0.0, 'train.epoch': 40, 'train.batch_size': 512, 'train.lr': 3.0000000000000004e-05}
3	4.253087997436523	0.49665791487817196	127.29876041412354	4.0513224601745605	0.45989304812834225	119.8399305343628	{'nn.hidden_size': 32, 'nn.output_size': 1, 'nn.num_layer': 2, 'nn.drop_prob': 0.0, 'train.epoch': 50, 'train.batch_size': 32, 'train.lr': 0.0001}
4	4.774425983428955	0.5137529983587931	153.6355972290039	4.079481601715088	0.5775401069518716	110.48352718353271	{'nn.hidden_size': 1024, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.25, 'train.epoch': 100, 'train.batch_size': 128, 'train.lr': 0.01}
5	6.1351423263549805	0.49973813675672263	354.01408672332764	5.101414680480957	0.5080213903743316	331.679105758667	{'nn.hidden_size': 256, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.5, 'train.epoch': 150, 'train.batch_size': 32, 'train.lr': 0.001}
6	4.77966833114624	0.5064943070635021	196.17173671722412	5.199986934661865	0.42780748663101603	223.13170433044434	{'nn.hidden_size': 32, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.25, 'train.epoch': 150, 'train.batch_size': 128, 'train.lr': 0.00030000000000000003}
7	4.307821273803711	0.5107615436813534	104.40298318862915	4.0367279052734375	0.5561497326203209	99.81648921966553	{'nn.hidden_size': 64, 'nn.output_size': 1, 'nn.num_layer': 2, 'nn.drop_prob': 0.25, 'train.epoch': 20, 'train.batch_size': 128, 'train.lr': 1e-05}
8	4.714599132537842	0.49995068488827166	116.42918586730957	4.072833061218262	0.5187165775401069	101.98783874511719	{'nn.hidden_size': 32, 'nn.output_size': 1, 'nn.num_layer': 2, 'nn.drop_prob': 0.25, 'train.epoch': 200, 'train.batch_size': 32, 'train.lr': 3.0000000000000004e-05}
9	5.92486572265625	0.500560712820351	337.99712657928467	5.252048492431641	0.5187165775401069	333.5186719894409	{'nn.hidden_size': 128, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.5, 'train.epoch': 50, 'train.batch_size': 512, 'train.lr': 0.003}
10	7.564241409301758	0.49615638019189495	438.466215133667	6.230506420135498	0.45989304812834225	330.97567558288574	{'nn.hidden_size': 32, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.0, 'train.epoch': 100, 'train.batch_size': 32, 'train.lr': 0.001}
11	4.607036590576172	0.4922003219290494	102.92174816131592	4.036316394805908	0.49732620320855614	101.26348733901978	{'nn.hidden_size': 128, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.0, 'train.epoch': 50, 'train.batch_size': 32, 'train.lr': 1e-05}
12	4.782899379730225	0.522420622396162	103.63278388977051	4.031926155090332	0.49732620320855614	101.63154602050781	{'nn.hidden_size': 64, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.5, 'train.epoch': 20, 'train.batch_size': 128, 'train.lr': 1e-05}
13	4.726716041564941	0.498643341276354	112.91052103042603	4.084372520446777	0.5026737967914439	107.13099241256714	{'nn.hidden_size': 64, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.5, 'train.epoch': 150, 'train.batch_size': 128, 'train.lr': 3.0000000000000004e-05}
14	6.17996883392334	0.49682213420022725	348.0748653411865	4.497281074523926	0.5294117647058824	252.06429958343506	{'nn.hidden_size': 32, 'nn.output_size': 1, 'nn.num_layer': 2, 'nn.drop_prob': 0.0, 'train.epoch': 100, 'train.batch_size': 128, 'train.lr': 0.001}
15	5.566521644592285	0.49697747680217147	370.3364133834839	4.836049556732178	0.5401069518716578	176.20822191238403	{'nn.hidden_size': 32, 'nn.output_size': 1, 'nn.num_layer': 2, 'nn.drop_prob': 0.5, 'train.epoch': 80, 'train.batch_size': 512, 'train.lr': 0.003}
16	7.396501541137695	0.49764865547279385	412.4086856842041	5.293024063110352	0.48128342245989303	277.40790843963623	{'nn.hidden_size': 128, 'nn.output_size': 1, 'nn.num_layer': 2, 'nn.drop_prob': 0.0, 'train.epoch': 50, 'train.batch_size': 32, 'train.lr': 0.001}
17	4.433727264404297	0.4901685393258427	151.78887844085693	4.122784614562988	0.5401069518716578	137.33948469161987	{'nn.hidden_size': 256, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.0, 'train.epoch': 40, 'train.batch_size': 128, 'train.lr': 0.30000000000000004}
18	4.954971790313721	0.4936797752808989	104.26409244537354	4.05362606048584	0.45454545454545453	102.38856077194214	{'nn.hidden_size': 128, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.25, 'train.epoch': 20, 'train.batch_size': 512, 'train.lr': 1e-05}
19	5.1422834396362305	0.4963210926650675	112.42586374282837	4.190701007843018	0.47058823529411764	109.20034646987915	{'nn.hidden_size': 128, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.5, 'train.epoch': 150, 'train.batch_size': 512, 'train.lr': 3.0000000000000004e-05}
20	4.918341636657715	0.5000532603206665	198.1989026069641	4.1095194816589355	0.48128342245989303	131.9919228553772	{'nn.hidden_size': 1024, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.0, 'train.epoch': 20, 'train.batch_size': 32, 'train.lr': 0.001}
21	5.294863700866699	0.502133371733367	158.13642740249634	4.248719215393066	0.4919786096256685	146.52341604232788	{'nn.hidden_size': 64, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.0, 'train.epoch': 150, 'train.batch_size': 128, 'train.lr': 0.03}
22	5.126774311065674	0.5005824114695114	139.1550064086914	4.102991104125977	0.5080213903743316	104.44018840789795	{'nn.hidden_size': 1024, 'nn.output_size': 1, 'nn.num_layer': 2, 'nn.drop_prob': 0.5, 'train.epoch': 40, 'train.batch_size': 32, 'train.lr': 3.0000000000000004e-05}
23	6.243885517120361	0.4959615855005681	369.90253925323486	5.063043594360352	0.5668449197860963	296.15769386291504	{'nn.hidden_size': 512, 'nn.output_size': 1, 'nn.num_layer': 2, 'nn.drop_prob': 0.0, 'train.epoch': 60, 'train.batch_size': 32, 'train.lr': 0.03}
24	6.361900806427002	0.4952736396919581	454.83078956604004	6.760718822479248	0.47058823529411764	415.76037406921387	{'nn.hidden_size': 1024, 'nn.output_size': 1, 'nn.num_layer': 2, 'nn.drop_prob': 0.5, 'train.epoch': 100, 'train.batch_size': 512, 'train.lr': 0.00030000000000000003}
25	4.939188480377197	0.4991507937760384	161.8463635444641	4.247941493988037	0.5133689839572193	122.70845174789429	{'nn.hidden_size': 1024, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.0, 'train.epoch': 100, 'train.batch_size': 32, 'train.lr': 1e-05}
26	6.569973945617676	0.49741983335437445	451.01752281188965	7.310329914093018	0.43315508021390375	401.50790214538574	{'nn.hidden_size': 256, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.5, 'train.epoch': 90, 'train.batch_size': 512, 'train.lr': 0.001}
27	5.839080333709717	0.4953841055422295	216.58790111541748	4.128775596618652	0.5721925133689839	118.77070665359497	{'nn.hidden_size': 256, 'nn.output_size': 1, 'nn.num_layer': 2, 'nn.drop_prob': 0.25, 'train.epoch': 50, 'train.batch_size': 512, 'train.lr': 0.00030000000000000003}
28	4.461141586303711	0.5133426966292135	102.62287855148315	4.040831089019775	0.5401069518716578	99.19891953468323	{'nn.hidden_size': 512, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.25, 'train.epoch': 30, 'train.batch_size': 32, 'train.lr': 0.003}
29	4.318927764892578	0.4996607120313092	107.0320725440979	4.080329895019531	0.5401069518716578	101.10979080200195	{'nn.hidden_size': 256, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.5, 'train.epoch': 90, 'train.batch_size': 128, 'train.lr': 1e-05}
30	5.420880317687988	0.49624514739300596	196.9927430152893	4.921666145324707	0.4919786096256685	164.28920030593872	{'nn.hidden_size': 64, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.25, 'train.epoch': 90, 'train.batch_size': 512, 'train.lr': 0.00030000000000000003}
31	6.075620651245117	0.499108382779952	334.68430042266846	6.996364116668701	0.4385026737967914	395.1756715774536	{'nn.hidden_size': 512, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.25, 'train.epoch': 150, 'train.batch_size': 32, 'train.lr': 0.03}
32	4.98684549331665	0.5013956176619114	102.50110626220703	4.045341968536377	0.4919786096256685	101.94758176803589	{'nn.hidden_size': 256, 'nn.output_size': 1, 'nn.num_layer': 2, 'nn.drop_prob': 0.5, 'train.epoch': 70, 'train.batch_size': 512, 'train.lr': 1e-05}
33	5.0198540687561035	0.49534268084837774	279.0448188781738	4.596667766571045	0.47593582887700536	216.18964672088623	{'nn.hidden_size': 128, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.5, 'train.epoch': 50, 'train.batch_size': 32, 'train.lr': 0.00030000000000000003}
34	6.6783552169799805	0.4966130381264992	420.6484794616699	6.779788494110107	0.4117647058823529	314.9970769882202	{'nn.hidden_size': 128, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.25, 'train.epoch': 100, 'train.batch_size': 128, 'train.lr': 0.003}
35	5.541581630706787	0.4896443196881707	332.5528621673584	5.370950698852539	0.44919786096256686	347.48222827911377	{'nn.hidden_size': 256, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.25, 'train.epoch': 70, 'train.batch_size': 32, 'train.lr': 0.1}
36	4.767635822296143	0.5070224719101124	101.99321508407593	4.042654991149902	0.5401069518716578	99.53996539115906	{'nn.hidden_size': 1024, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.25, 'train.epoch': 60, 'train.batch_size': 128, 'train.lr': 0.001}
37	5.478694915771484	0.5033470166330009	240.36502838134766	4.605815410614014	0.48663101604278075	156.0155153274536	{'nn.hidden_size': 256, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.5, 'train.epoch': 30, 'train.batch_size': 32, 'train.lr': 0.03}
38	4.7650861740112305	0.4609641301603333	169.22236680984497	4.224270343780518	0.46524064171123	134.15886163711548	{'nn.hidden_size': 64, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.0, 'train.epoch': 100, 'train.batch_size': 32, 'train.lr': 0.01}
39	5.829983711242676	0.49947775296679714	355.2549123764038	5.109370231628418	0.48128342245989303	234.2721462249756	{'nn.hidden_size': 1024, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.5, 'train.epoch': 60, 'train.batch_size': 32, 'train.lr': 0.003}
40	4.861808776855469	0.49602520199469763	216.44434928894043	4.451806545257568	0.5080213903743316	157.59600400924683	{'nn.hidden_size': 512, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.25, 'train.epoch': 30, 'train.batch_size': 32, 'train.lr': 0.01}
41	7.163516044616699	0.49578158534275973	464.4530773162842	5.259919166564941	0.48663101604278075	229.3405532836914	{'nn.hidden_size': 64, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.0, 'train.epoch': 150, 'train.batch_size': 32, 'train.lr': 0.003}
42	5.956416606903076	0.4981861901906325	288.84427547454834	4.593244552612305	0.47058823529411764	215.4912233352661	{'nn.hidden_size': 128, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.5, 'train.epoch': 200, 'train.batch_size': 32, 'train.lr': 0.0001}
43	7.798567771911621	0.4977019157934604	466.23520851135254	5.951557159423828	0.45989304812834225	323.7743377685547	{'nn.hidden_size': 64, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.0, 'train.epoch': 100, 'train.batch_size': 32, 'train.lr': 0.003}
44	5.394820690155029	0.49554684541093297	172.59408235549927	4.075710296630859	0.46524064171123	108.95754098892212	{'nn.hidden_size': 1024, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.25, 'train.epoch': 300, 'train.batch_size': 512, 'train.lr': 3.0000000000000004e-05}
45	6.520909786224365	0.49721369618735006	387.21113204956055	5.08302640914917	0.4385026737967914	249.89359378814697	{'nn.hidden_size': 512, 'nn.output_size': 1, 'nn.num_layer': 2, 'nn.drop_prob': 0.0, 'train.epoch': 70, 'train.batch_size': 128, 'train.lr': 0.001}
46	4.664794921875	0.5005316169044313	192.30499267578125	4.4838738441467285	0.48128342245989303	138.90150785446167	{'nn.hidden_size': 128, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.5, 'train.epoch': 70, 'train.batch_size': 512, 'train.lr': 0.00030000000000000003}
47	4.346929550170898	0.494209419580861	159.3037724494934	4.180788516998291	0.48663101604278075	113.72244358062744	{'nn.hidden_size': 1024, 'nn.output_size': 1, 'nn.num_layer': 1, 'nn.drop_prob': 0.0, 'train.epoch': 50, 'train.batch_size': 512, 'train.lr': 0.0001}
48	5.020261287689209	0.4968004355510668	124.00904893875122	4.1228203773498535	0.4385026737967914	112.63620853424072	{'nn.hidden_size': 256, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.25, 'train.epoch': 20, 'train.batch_size': 128, 'train.lr': 0.0001}
49	4.520392417907715	0.5007924938454741	112.04454898834229	4.098085880279541	0.48663101604278075	101.18389129638672	{'nn.hidden_size': 256, 'nn.output_size': 1, 'nn.num_layer': 3, 'nn.drop_prob': 0.25, 'train.epoch': 80, 'train.batch_size': 128, 'train.lr': 1e-05}
50	5.976629257202148	0.4967550656482767	309.70170497894287	5.5096611976623535	0.49732620320855614	240.1169776916504	{'nn.hidden_size': 256, 'nn.output_size': 1, 'nn.num_layer': 2, 'nn.drop_prob': 0.5, 'train.epoch': 300, 'train.batch_size': 512, 'train.lr': 0.30000000000000004}
